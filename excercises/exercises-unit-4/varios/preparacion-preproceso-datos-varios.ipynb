{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aff52ea-49a1-423a-a6d4-8743cfff161a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba89cf5-f501-4cca-ac8f-bb95bf982929",
   "metadata": {},
   "source": [
    "## Acceso a datos mediante ficheros en Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c18a7108-5cd8-4d1a-bc67-d648a6a9205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accidentes = pd.read_csv('./2019_Accidentalidad.csv',\n",
    "                         delimiter=';',\n",
    "                         encoding='latin1',\n",
    "                         parse_dates=['FECHA'],\n",
    "                         na_values=['-', 'DESCONOCIDA', 'DESCONOCIDO'])\n",
    "\n",
    "accidentes.to_parquet('./accidentes1.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f098fec4-edf0-49d5-a473-588ddc972a95",
   "metadata": {},
   "source": [
    "## Acceso a datos mediante API públicas en Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "479f5946-6075-40b8-b460-73728dec19f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f6ae55b-96c3-4971-b74f-98a03e242cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>node_id</th>\n",
       "      <th>name</th>\n",
       "      <th>full_name</th>\n",
       "      <th>private</th>\n",
       "      <th>owner</th>\n",
       "      <th>html_url</th>\n",
       "      <th>description</th>\n",
       "      <th>fork</th>\n",
       "      <th>url</th>\n",
       "      <th>...</th>\n",
       "      <th>allow_forking</th>\n",
       "      <th>is_template</th>\n",
       "      <th>web_commit_signoff_required</th>\n",
       "      <th>topics</th>\n",
       "      <th>visibility</th>\n",
       "      <th>forks</th>\n",
       "      <th>open_issues</th>\n",
       "      <th>watchers</th>\n",
       "      <th>default_branch</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>843222</td>\n",
       "      <td>MDEwOlJlcG9zaXRvcnk4NDMyMjI=</td>\n",
       "      <td>scikit-learn</td>\n",
       "      <td>scikit-learn/scikit-learn</td>\n",
       "      <td>False</td>\n",
       "      <td>{'login': 'scikit-learn', 'id': 365630, 'node_...</td>\n",
       "      <td>https://github.com/scikit-learn/scikit-learn</td>\n",
       "      <td>scikit-learn: machine learning in Python</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/scikit-learn/scik...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[data-analysis, data-science, machine-learning...</td>\n",
       "      <td>public</td>\n",
       "      <td>24840</td>\n",
       "      <td>2261</td>\n",
       "      <td>56327</td>\n",
       "      <td>main</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>858127</td>\n",
       "      <td>MDEwOlJlcG9zaXRvcnk4NTgxMjc=</td>\n",
       "      <td>pandas</td>\n",
       "      <td>pandas-dev/pandas</td>\n",
       "      <td>False</td>\n",
       "      <td>{'login': 'pandas-dev', 'id': 21206976, 'node_...</td>\n",
       "      <td>https://github.com/pandas-dev/pandas</td>\n",
       "      <td>Flexible and powerful data analysis / manipula...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[alignment, data-analysis, data-science, flexi...</td>\n",
       "      <td>public</td>\n",
       "      <td>16885</td>\n",
       "      <td>3692</td>\n",
       "      <td>40231</td>\n",
       "      <td>main</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>204086862</td>\n",
       "      <td>MDEwOlJlcG9zaXRvcnkyMDQwODY4NjI=</td>\n",
       "      <td>streamlit</td>\n",
       "      <td>streamlit/streamlit</td>\n",
       "      <td>False</td>\n",
       "      <td>{'login': 'streamlit', 'id': 45109972, 'node_i...</td>\n",
       "      <td>https://github.com/streamlit/streamlit</td>\n",
       "      <td>Streamlit — A faster way to build and share da...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/streamlit/streamlit</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[data-analysis, data-science, data-visualizati...</td>\n",
       "      <td>public</td>\n",
       "      <td>2520</td>\n",
       "      <td>687</td>\n",
       "      <td>28294</td>\n",
       "      <td>develop</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>162405963</td>\n",
       "      <td>MDEwOlJlcG9zaXRvcnkxNjI0MDU5NjM=</td>\n",
       "      <td>gradio</td>\n",
       "      <td>gradio-app/gradio</td>\n",
       "      <td>False</td>\n",
       "      <td>{'login': 'gradio-app', 'id': 51063788, 'node_...</td>\n",
       "      <td>https://github.com/gradio-app/gradio</td>\n",
       "      <td>Build and share delightful machine learning ap...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/gradio-app/gradio</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[data-analysis, data-science, data-visualizati...</td>\n",
       "      <td>public</td>\n",
       "      <td>1647</td>\n",
       "      <td>464</td>\n",
       "      <td>23220</td>\n",
       "      <td>main</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>283046497</td>\n",
       "      <td>MDEwOlJlcG9zaXRvcnkyODMwNDY0OTc=</td>\n",
       "      <td>airbyte</td>\n",
       "      <td>airbytehq/airbyte</td>\n",
       "      <td>False</td>\n",
       "      <td>{'login': 'airbytehq', 'id': 59758427, 'node_i...</td>\n",
       "      <td>https://github.com/airbytehq/airbyte</td>\n",
       "      <td>Data integration platform for ELT pipelines fr...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/airbytehq/airbyte</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[airbyte, bigquery, change-data-capture, data,...</td>\n",
       "      <td>public</td>\n",
       "      <td>3181</td>\n",
       "      <td>5094</td>\n",
       "      <td>12202</td>\n",
       "      <td>master</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                           node_id          name  \\\n",
       "0     843222      MDEwOlJlcG9zaXRvcnk4NDMyMjI=  scikit-learn   \n",
       "1     858127      MDEwOlJlcG9zaXRvcnk4NTgxMjc=        pandas   \n",
       "2  204086862  MDEwOlJlcG9zaXRvcnkyMDQwODY4NjI=     streamlit   \n",
       "3  162405963  MDEwOlJlcG9zaXRvcnkxNjI0MDU5NjM=        gradio   \n",
       "4  283046497  MDEwOlJlcG9zaXRvcnkyODMwNDY0OTc=       airbyte   \n",
       "\n",
       "                   full_name  private  \\\n",
       "0  scikit-learn/scikit-learn    False   \n",
       "1          pandas-dev/pandas    False   \n",
       "2        streamlit/streamlit    False   \n",
       "3          gradio-app/gradio    False   \n",
       "4          airbytehq/airbyte    False   \n",
       "\n",
       "                                               owner  \\\n",
       "0  {'login': 'scikit-learn', 'id': 365630, 'node_...   \n",
       "1  {'login': 'pandas-dev', 'id': 21206976, 'node_...   \n",
       "2  {'login': 'streamlit', 'id': 45109972, 'node_i...   \n",
       "3  {'login': 'gradio-app', 'id': 51063788, 'node_...   \n",
       "4  {'login': 'airbytehq', 'id': 59758427, 'node_i...   \n",
       "\n",
       "                                       html_url  \\\n",
       "0  https://github.com/scikit-learn/scikit-learn   \n",
       "1          https://github.com/pandas-dev/pandas   \n",
       "2        https://github.com/streamlit/streamlit   \n",
       "3          https://github.com/gradio-app/gradio   \n",
       "4          https://github.com/airbytehq/airbyte   \n",
       "\n",
       "                                         description   fork  \\\n",
       "0           scikit-learn: machine learning in Python  False   \n",
       "1  Flexible and powerful data analysis / manipula...  False   \n",
       "2  Streamlit — A faster way to build and share da...  False   \n",
       "3  Build and share delightful machine learning ap...  False   \n",
       "4  Data integration platform for ELT pipelines fr...  False   \n",
       "\n",
       "                                                 url  ... allow_forking  \\\n",
       "0  https://api.github.com/repos/scikit-learn/scik...  ...          True   \n",
       "1     https://api.github.com/repos/pandas-dev/pandas  ...          True   \n",
       "2   https://api.github.com/repos/streamlit/streamlit  ...          True   \n",
       "3     https://api.github.com/repos/gradio-app/gradio  ...          True   \n",
       "4     https://api.github.com/repos/airbytehq/airbyte  ...          True   \n",
       "\n",
       "  is_template web_commit_signoff_required  \\\n",
       "0       False                       False   \n",
       "1       False                       False   \n",
       "2       False                       False   \n",
       "3       False                       False   \n",
       "4       False                       False   \n",
       "\n",
       "                                              topics visibility  forks  \\\n",
       "0  [data-analysis, data-science, machine-learning...     public  24840   \n",
       "1  [alignment, data-analysis, data-science, flexi...     public  16885   \n",
       "2  [data-analysis, data-science, data-visualizati...     public   2520   \n",
       "3  [data-analysis, data-science, data-visualizati...     public   1647   \n",
       "4  [airbyte, bigquery, change-data-capture, data,...     public   3181   \n",
       "\n",
       "  open_issues watchers default_branch score  \n",
       "0        2261    56327           main   1.0  \n",
       "1        3692    40231           main   1.0  \n",
       "2         687    28294        develop   1.0  \n",
       "3         464    23220           main   1.0  \n",
       "4        5094    12202         master   1.0  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request_header = {'Accept':'application/vnd.github.v3+json'}\n",
    "\n",
    "url_base = 'https://api.github.com/search/repositories?'\n",
    "\n",
    "query = 'q=topic:data-analysis+language:Python&sort=stars&order=desc'\n",
    "\n",
    "response = requests.get(url_base + query, headers = request_header)\n",
    "\n",
    "\n",
    "librerias = pd.DataFrame(response.json()['items'])\n",
    "\n",
    "librerias.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c566c18-17b0-4514-bebd-7483710f2623",
   "metadata": {},
   "source": [
    "##  Acceso a datos públicos mediante web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dc91675-b2c4-4c0f-9613-c593ed1a50f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valor</th>\n",
       "      <th>Último</th>\n",
       "      <th>Var. %</th>\n",
       "      <th>Var.</th>\n",
       "      <th>Ac. % año</th>\n",
       "      <th>Máx.</th>\n",
       "      <th>Mín.</th>\n",
       "      <th>Vol.</th>\n",
       "      <th>Capit.</th>\n",
       "      <th>Hora</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACCIONA</td>\n",
       "      <td>127,400</td>\n",
       "      <td>0,16</td>\n",
       "      <td>0,20</td>\n",
       "      <td>-23,63</td>\n",
       "      <td>127,850</td>\n",
       "      <td>126,350</td>\n",
       "      <td>21.661</td>\n",
       "      <td>6.989</td>\n",
       "      <td>11:46</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACCIONA ENER</td>\n",
       "      <td>27,580</td>\n",
       "      <td>0,00</td>\n",
       "      <td>0,00</td>\n",
       "      <td>-22,00</td>\n",
       "      <td>27,900</td>\n",
       "      <td>27,400</td>\n",
       "      <td>56.962</td>\n",
       "      <td>9.081</td>\n",
       "      <td>11:46</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACERINOX</td>\n",
       "      <td>9,694</td>\n",
       "      <td>0,33</td>\n",
       "      <td>0,03</td>\n",
       "      <td>11,34</td>\n",
       "      <td>9,784</td>\n",
       "      <td>9,652</td>\n",
       "      <td>389.950</td>\n",
       "      <td>2.417</td>\n",
       "      <td>11:46</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACS</td>\n",
       "      <td>33,490</td>\n",
       "      <td>-1,18</td>\n",
       "      <td>-0,40</td>\n",
       "      <td>33,63</td>\n",
       "      <td>33,890</td>\n",
       "      <td>33,460</td>\n",
       "      <td>35.979</td>\n",
       "      <td>9.316</td>\n",
       "      <td>11:46</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AENA</td>\n",
       "      <td>145,950</td>\n",
       "      <td>0,45</td>\n",
       "      <td>0,65</td>\n",
       "      <td>28,41</td>\n",
       "      <td>147,150</td>\n",
       "      <td>145,350</td>\n",
       "      <td>18.414</td>\n",
       "      <td>21.892</td>\n",
       "      <td>11:46</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Valor   Último Var. %   Var. Ac. % año     Máx.     Mín.     Vol.  \\\n",
       "0       ACCIONA  127,400   0,16   0,20    -23,63  127,850  126,350   21.661   \n",
       "1  ACCIONA ENER   27,580   0,00   0,00    -22,00   27,900   27,400   56.962   \n",
       "2      ACERINOX    9,694   0,33   0,03     11,34    9,784    9,652  389.950   \n",
       "3           ACS   33,490  -1,18  -0,40     33,63   33,890   33,460   35.979   \n",
       "4          AENA  145,950   0,45   0,65     28,41  147,150  145,350   18.414   \n",
       "\n",
       "   Capit.   Hora    \n",
       "0   6.989  11:46    \n",
       "1   9.081  11:46    \n",
       "2   2.417  11:46    \n",
       "3   9.316  11:46    \n",
       "4  21.892  11:46    "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import requests\n",
    "\n",
    "URL = 'https://www.expansion.com/mercados/cotizaciones/indices/ibex35_I.IB.html'\n",
    "\n",
    "pagina = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(pagina.content, 'html.parser')\n",
    "\n",
    "\n",
    "# Inspeccionando el HTML de la página vemos que las cotizaciones aparecen\n",
    "# en un elemento de tipo table con el id 'listado_valores'\n",
    "\n",
    "tabla = soup.find(id = 'listado_valores')\n",
    "\n",
    "\n",
    "# Dentro de esa tabla hay un elemento de tipo thead con los títulos,\n",
    "# que seleccionamos para dar nombre a las columnas del dataframe\n",
    "\n",
    "columnas = [th.text.strip() for th in tabla.find('thead').find_all('th')]\n",
    "\n",
    "\n",
    "# Dentro de esa tabla los datos están organizados en filas (td) y columnas (tr)\n",
    "# La primera fila está vacía y la descartamos\n",
    "\n",
    "datos = [[td.text for td in tr.find_all('td')] for tr in tabla.find_all('tr')[1:]]\n",
    "\n",
    "\n",
    "# Creamos un dataframe con los datos extraídos\n",
    "\n",
    "cotizaciones = pd.DataFrame(datos, columns=columnas)\n",
    "\n",
    "cotizaciones.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8fc31a-9d3d-45bb-8b80-b828f1d6e033",
   "metadata": {},
   "source": [
    "## Ejemplo de estandarización de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "645bc03b-5ee8-4cc2-9ff0-24ebdd888e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cf/7nzhdlvs5nl0_zh6ky9hz9vc0000gn/T/ipykernel_4284/3622968138.py:11: PerformanceWarning: Adding/subtracting object-dtype array to TimedeltaArray not vectorized.\n",
      "  accidentes['FECHA'] += pd.to_timedelta(accidentes.HORA + ' :00')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'Timedelta' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 11\u001b[0m\n\u001b[1;32m      5\u001b[0m accidentes \u001b[38;5;241m=\u001b[39m accidentes\u001b[38;5;241m.\u001b[39miloc[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Decodificamos la hora y la añadimos a la fecha para tener un campo\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# de tipo fecha-hora, más fácil de utilizar\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[43maccidentes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFECHA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_timedelta\u001b[49m\u001b[43m(\u001b[49m\u001b[43maccidentes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHORA\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m :00\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Eliminamos columnas que ya no son necesarias\u001b[39;00m\n\u001b[1;32m     16\u001b[0m accidentes \u001b[38;5;241m=\u001b[39m accidentes\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHORA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCALLE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNÚMERO\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/generic.py:11792\u001b[0m, in \u001b[0;36mNDFrame.__iadd__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m  11790\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iadd__\u001b[39m(\u001b[38;5;28mself\u001b[39m: NDFrameT, other) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[1;32m  11791\u001b[0m     \u001b[38;5;66;03m# error: Unsupported left operand type for + (\"Type[NDFrame]\")\u001b[39;00m\n\u001b[0;32m> 11792\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inplace_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__add__\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/generic.py:11765\u001b[0m, in \u001b[0;36mNDFrame._inplace_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m  11760\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m  11761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_inplace_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[1;32m  11762\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m  11763\u001b[0m \u001b[38;5;124;03m    Wrap arithmetic method to operate inplace.\u001b[39;00m\n\u001b[1;32m  11764\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m> 11765\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m  11767\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m  11768\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m  11769\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_indexed_same(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11773\u001b[0m         \u001b[38;5;66;03m# Item \"ArrayManager\" of \"Union[ArrayManager, SingleArrayManager,\u001b[39;00m\n\u001b[1;32m  11774\u001b[0m         \u001b[38;5;66;03m# BlockManager, SingleBlockManager]\" has no attribute \"setitem_inplace\"\u001b[39;00m\n\u001b[1;32m  11775\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39msetitem_inplace(  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m  11776\u001b[0m             \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m), result\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m  11777\u001b[0m         )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/ops/common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     79\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/arraylike.py:186\u001b[0m, in \u001b[0;36mOpsMixin.__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__add__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__add__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m    100\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    Get Addition of DataFrame and other, column-wise.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03m    moose     3.0     NaN\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/series.py:6112\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[1;32m   6111\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39malign_method_SERIES(\u001b[38;5;28mself\u001b[39m, other)\n\u001b[0;32m-> 6112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexOpsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/base.py:1348\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   1345\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m ensure_wrapped_if_datetimelike(rvalues)\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1348\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(result, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/ops/array_ops.py:224\u001b[0m, in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;66;03m# NB: We assume that extract_array and ensure_wrapped_if_datetimelike\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m#  have already been called on `left` and `right`,\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m#  and `maybe_prepare_scalar_for_op` has already been called on `right`\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m# We need to special-case datetime64/timedelta64 dtypes (e.g. because numpy\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# casts integer dtypes to timedelta64 when operating with timedelta64 - GH#22390)\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    218\u001b[0m     should_extension_dispatch(left, right)\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(right, (Timedelta, BaseOffset, Timestamp))\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# Timedelta/Timestamp and other custom scalars are included in the check\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m# because numexpr will fail on it, see GH#31457\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;66;03m# TODO we should handle EAs consistently and move this check before the if/else\u001b[39;00m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# (https://github.com/pandas-dev/pandas/issues/41165)\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     _bool_arith_check(op, left, right)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/arrays/datetimelike.py:1993\u001b[0m, in \u001b[0;36mTimelikeOps.__array_ufunc__\u001b[0;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1985\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1986\u001b[0m     ufunc \u001b[38;5;129;01min\u001b[39;00m [np\u001b[38;5;241m.\u001b[39misnan, np\u001b[38;5;241m.\u001b[39misinf, np\u001b[38;5;241m.\u001b[39misfinite]\n\u001b[1;32m   1987\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1988\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m inputs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   1989\u001b[0m ):\n\u001b[1;32m   1990\u001b[0m     \u001b[38;5;66;03m# numpy 1.18 changed isinf and isnan to not raise on dt64/td64\u001b[39;00m\n\u001b[1;32m   1991\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ufunc, method)(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ndarray, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1993\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__array_ufunc__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mufunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/arrays/base.py:1668\u001b[0m, in \u001b[0;36mExtensionArray.__array_ufunc__\u001b[0;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m   1664\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(other, (ABCSeries, ABCIndex, ABCDataFrame)) \u001b[38;5;28;01mfor\u001b[39;00m other \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m   1665\u001b[0m ):\n\u001b[1;32m   1666\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m-> 1668\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43marraylike\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_dispatch_ufunc_to_dunder_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mufunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1672\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/_libs/ops_dispatch.pyx:113\u001b[0m, in \u001b[0;36mpandas._libs.ops_dispatch.maybe_dispatch_ufunc_to_dunder_op\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/arrays/datetimelike.py:1369\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin.__radd__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__radd__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m   1368\u001b[0m     \u001b[38;5;66;03m# alias for __add__\u001b[39;00m\n\u001b[0;32m-> 1369\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__add__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/ops/common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     79\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/arrays/datetimelike.py:1344\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin.__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1341\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_timedelta_arraylike(other)\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_object_dtype(other_dtype):\n\u001b[1;32m   1343\u001b[0m     \u001b[38;5;66;03m# e.g. Array/Index of DateOffset objects\u001b[39;00m\n\u001b[0;32m-> 1344\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_addsub_object_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1345\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_datetime64_dtype(other_dtype) \u001b[38;5;129;01mor\u001b[39;00m is_datetime64tz_dtype(other_dtype):\n\u001b[1;32m   1346\u001b[0m     \u001b[38;5;66;03m# DatetimeIndex, ndarray[datetime64]\u001b[39;00m\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_datetime_arraylike(other)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/arrays/datetimelike.py:1299\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin._addsub_object_array\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;66;03m# Caller is responsible for broadcasting if necessary\u001b[39;00m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m other\u001b[38;5;241m.\u001b[39mshape, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, other\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m-> 1299\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mO\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'Timedelta' and 'str'"
     ]
    }
   ],
   "source": [
    "# Leemos los datos anteriormente guardados, y descartamos la última columna\n",
    "\n",
    "accidentes = pd.read_parquet('./accidentes1.parquet')\n",
    "\n",
    "accidentes = accidentes.iloc[:, :-1]\n",
    "\n",
    "\n",
    "# Decodificamos la hora y la añadimos a la fecha para tener un campo\n",
    "# de tipo fecha-hora, más fácil de utilizar\n",
    "\n",
    "accidentes['FECHA'] += pd.to_timedelta(accidentes.HORA + ':00')\n",
    "\n",
    "\n",
    "# Eliminamos columnas que ya no son necesarias\n",
    "\n",
    "accidentes = accidentes.drop(columns=['HORA', 'CALLE', 'NÚMERO'])\n",
    "\n",
    "\n",
    "# Convertimos todas las columnas a partir de la tercera en tipos categóricos\n",
    "# (o sea, con un número predefinido de opciones posibles)\n",
    "\n",
    "accidentes.iloc[:,2:] = accidentes.iloc[:,2:].astype('category')\n",
    "\n",
    "\n",
    "# Generamos un nuevo campo que codiﬁque los niveles de gravedad en función de\n",
    "# la \"lesividad\", según se especiﬁca en el documento de descripción de los datos\n",
    "\n",
    "c_gravedad = pd.api.types.CategoricalDtype(categories = ['Ileso', 'Leve', 'Grave', 'Fallecido'], ordered=True)\n",
    "\n",
    "dict_gravedad = {14.0: 'Ileso', 3.0: 'Grave', 4.0: 'Fallecido'}\n",
    "\n",
    "accidentes['GRAVEDAD'] = accidentes['lesividad*'].apply(lambda x: dict_gravedad.get(x,'Leve') if ~np.isnan(x) else 'Ileso').astype(c_gravedad)\n",
    "\n",
    "\n",
    "# Guardamos el resultado para análisis posteriores\n",
    "\n",
    "accidentes.to_parquet('./accidentes2.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f2284f-3dd1-4dd5-8362-7e98ab2c835d",
   "metadata": {},
   "source": [
    "## Ejemplo de ajuste de la granularidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d1c6ad3-c106-45b4-bc8a-1163b4438a64",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './01-2019.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfecha\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtipo_elem\u001b[39m\u001b[38;5;124m'\u001b[39m])\\\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;241m.\u001b[39magg({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintensidad\u001b[39m\u001b[38;5;124m'\u001b[39m : np\u001b[38;5;241m.\u001b[39msum, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mocupacion\u001b[39m\u001b[38;5;124m'\u001b[39m : np\u001b[38;5;241m.\u001b[39mmean, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcarga\u001b[39m\u001b[38;5;124m'\u001b[39m : np\u001b[38;5;241m.\u001b[39mmean})\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Generamos los nombres de fichero para cada mes y concatenamos los datos\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mn\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m02d\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-2019.zip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m13\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Guardamos los datos para su uso posterior\u001b[39;00m\n\u001b[1;32m     18\u001b[0m df\u001b[38;5;241m.\u001b[39mreset_index()\u001b[38;5;241m.\u001b[39mto_parquet(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrafico1.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/reshape/concat.py:372\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    370\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/reshape/concat.py:426\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    424\u001b[0m     objs \u001b[38;5;241m=\u001b[39m [objs[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m keys]\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 426\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfecha\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtipo_elem\u001b[39m\u001b[38;5;124m'\u001b[39m])\\\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;241m.\u001b[39magg({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintensidad\u001b[39m\u001b[38;5;124m'\u001b[39m : np\u001b[38;5;241m.\u001b[39msum, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mocupacion\u001b[39m\u001b[38;5;124m'\u001b[39m : np\u001b[38;5;241m.\u001b[39mmean, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcarga\u001b[39m\u001b[38;5;124m'\u001b[39m : np\u001b[38;5;241m.\u001b[39mmean})\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Generamos los nombres de fichero para cada mes y concatenamos los datos\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat((\u001b[43mget_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mn\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m02d\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-2019.zip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m13\u001b[39m)))\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Guardamos los datos para su uso posterior\u001b[39;00m\n\u001b[1;32m     18\u001b[0m df\u001b[38;5;241m.\u001b[39mreset_index()\u001b[38;5;241m.\u001b[39mto_parquet(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrafico1.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m, in \u001b[0;36mget_file\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_file\u001b[39m(name):\n\u001b[0;32m----> 5\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m;\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfecha\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfecha\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtipo_elem\u001b[39m\u001b[38;5;124m'\u001b[39m])\\\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;241m.\u001b[39magg({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintensidad\u001b[39m\u001b[38;5;124m'\u001b[39m : np\u001b[38;5;241m.\u001b[39msum, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mocupacion\u001b[39m\u001b[38;5;124m'\u001b[39m : np\u001b[38;5;241m.\u001b[39mmean, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcarga\u001b[39m\u001b[38;5;124m'\u001b[39m : np\u001b[38;5;241m.\u001b[39mmean})\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/common.py:782\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;66;03m# ZIP Compression\u001b[39;00m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m compression \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;00m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;66;03m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;66;03m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;00m\n\u001b[0;32m--> 782\u001b[0m     handle \u001b[38;5;241m=\u001b[39m \u001b[43m_BytesZipFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcompression_args\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m handle\u001b[38;5;241m.\u001b[39mbuffer\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    786\u001b[0m         handles\u001b[38;5;241m.\u001b[39mappend(handle)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/common.py:1025\u001b[0m, in \u001b[0;36m_BytesZipFile.__init__\u001b[0;34m(self, file, mode, archive_name, **kwargs)\u001b[0m\n\u001b[1;32m   1021\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, zipfile\u001b[38;5;241m.\u001b[39mZIP_DEFLATED)\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# error: Argument 1 to \"ZipFile\" has incompatible type \"Union[\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;66;03m# Union[str, PathLike[str]], ReadBuffer[bytes], WriteBuffer[bytes]]\";\u001b[39;00m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;66;03m# expected \"Union[Union[str, PathLike[str]], IO[bytes]]\"\u001b[39;00m\n\u001b[0;32m-> 1025\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m=\u001b[39m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.6/Frameworks/Python.framework/Versions/3.11/lib/python3.11/zipfile.py:1284\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1284\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilemode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1285\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   1286\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './01-2019.zip'"
     ]
    }
   ],
   "source": [
    "# Esta función devuelve un dataframe con los datos ya consolidados para un fichero concreto\n",
    "\n",
    "def get_file(name):\n",
    "    \n",
    "    df = pd.read_csv(name, sep=';', parse_dates=['fecha'])\n",
    "\n",
    "    return df.groupby(['fecha', 'tipo_elem'])\\\n",
    "        .agg({'intensidad' : np.sum, 'ocupacion' : np.mean, 'carga' : np.mean})\n",
    "\n",
    "\n",
    "# Generamos los nombres de fichero para cada mes y concatenamos los datos\n",
    "\n",
    "df = pd.concat((get_file(f'./{n:02d}-2019.zip') for n in range(1,13)))\n",
    "\n",
    "\n",
    "# Guardamos los datos para su uso posterior\n",
    "\n",
    "df.reset_index().to_parquet('trafico1.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0060a729-f87f-40d5-9f09-b65f40082fcb",
   "metadata": {},
   "source": [
    "## Ejemplo de generación de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22d647e-df36-4c1b-96a0-f95ad61fc876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos los datos de accidentes limpios anteriormente guardados\n",
    "\n",
    "accidentes = pd.read_parquet('./accidentes2.parquet')\n",
    "\n",
    "\n",
    "# Calculamos el número de personas implicadas en accidentes por\n",
    "# tipo de vehículo y por gravedad (solo conductores, no pasajeros)\n",
    "\n",
    "grav = accidentes[accidentes['TIPO PERSONA'] == 'Conductor']\\\n",
    "    .groupby(['TIPO VEHÍCULO','GRAVEDAD'])['Nº EXPEDIENTE'].nunique()\n",
    "\n",
    "\n",
    "# Calculamos el porcentaje de graves, leves, etc. para el total de\n",
    "# los accidentes y para cada tipo de vehículo\n",
    "\n",
    "grav_rel = grav.groupby('GRAVEDAD').sum() / grav.sum()\n",
    "grav_rel_veh = grav / grav.groupby('TIPO VEHÍCULO').sum()\n",
    "\n",
    "\n",
    "# Generamos un indicador que compara la gravedad para los accidentados\n",
    "# por en tipo de vehículo con la gravedad general\n",
    "\n",
    "grav_ratio = (grav_rel_veh / grav_rel) - 1\n",
    "\n",
    "\n",
    "# Seleccionamos los nueve tipos de vehículos más comunes y mostramos los datos\n",
    "# en una tabla\n",
    "\n",
    "top_accidentes = accidentes['TIPO VEHÍCULO']\\\n",
    ".value_counts().head(9).index.values\n",
    "grav_ratio[top_accidentes].unstack(1).loc[top_accidentes].style.format(\"{:.0%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5062c7cb-2cdb-4a66-a1a4-8d5c6a14d611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "\n",
    "# Leemos los datos de accidentes limpios anteriormente guardados\n",
    "\n",
    "trafico = pd.read_parquet('./trafico1.parquet')\n",
    "\n",
    "\n",
    "# Generamos la media del indicador de ocupación de las calles en función\n",
    "# de dos variables sintéticas: la hora del día y el día de la semana\n",
    "\n",
    "data = trafico.groupby([trafico.fecha.dt.hour, trafico.fecha.dt.dayofweek])\\\n",
    "    ['ocupacion'].mean().rename_axis(['HORA', 'DIA DE LA SEMANA']).reset_index()\n",
    "\n",
    "\n",
    "# Creamos un sencillo heatmap para mostrar los resultados\n",
    "\n",
    "alt.Chart(data).mark_rect().encode(\n",
    "    x='HORA:O',\n",
    "    y='DIA DE LA SEMANA:O',\n",
    "    color=alt.Color('ocupacion:Q', legend = None))\\\n",
    ".properties(title='Densidad de tráfico en Madrid (2019)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5136e680-3c12-4f5d-b52e-c8d15b137da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos los datos de accidentes y de tráfico\n",
    "\n",
    "accidentes = pd.read_parquet('./accidentes2.parquet')\n",
    "\n",
    "trafico = pd.read_parquet('./trafico1.parquet')\n",
    "\n",
    "\n",
    "# Generamos indicadores de accidentalidad y de intensidad de tráfico\n",
    "\n",
    "data_a = accidentes.groupby([accidentes.FECHA.dt.hour, accidentes.FECHA.dt.dayofweek])\\\n",
    "\n",
    "    ['Nº EXPEDIENTE'].count().rename_axis(['HORA', 'DIA DE LA SEMANA'])\n",
    "\n",
    "\n",
    "data_t = trafico[trafico['tipo_elem'] == 'URB']\\\n",
    "\n",
    "    .groupby([trafico.fecha.dt.hour, trafico.fecha.dt.dayofweek])\\\n",
    "\n",
    "    ['carga'].mean().rename_axis(['HORA', 'DIA DE LA SEMANA'])\n",
    "\n",
    "\n",
    "# Con los datos alineados, hacemos el ratio entre los dos indicadores\n",
    "\n",
    "data = (data_a / data_t).rename('Accidentalidad').reset_index()\n",
    "\n",
    "\n",
    "# Creamos un sencillo heatmap para mostrar los resultados\n",
    "\n",
    "alt.Chart(data).mark_rect().encode(\n",
    "    x='HORA:O',\n",
    "    y='DIA DE LA SEMANA:O',\n",
    "    color=alt.Color('Accidentalidad:Q',\n",
    "        scale=alt.Scale(scheme=\"lightorange\"),legend = None)\n",
    "    ).properties(title='Relación entre accidentalidad y carga de trafico')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
